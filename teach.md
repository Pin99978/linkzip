# LinkZip 架構師學習日誌

這份文件旨在記錄 LinkZip 開發過程中的技術決策與架構思考，幫助 PM 理解每個選擇背後的權衡與考量。

---

## 第一章：後端 MVP 架構設計

**紀錄者：** 後端工程師

### 1. 框架選擇：為什麼是 FastAPI？

*   **高性能**: FastAPI 是基於 Starlette 和 Pydantic 建立的，其非同步 (Async) 特性讓它成為 Python Web 框架中性能的佼佼者，非常適合需要處理大量 I/O 請求的應用（例如我們的網址重定向）。
*   **開發效率**: 它利用 Python 的類型提示 (Type Hints) 來自動驗證傳入的請求資料，並自動生成互動式 API 文件 (Swagger UI)。這意味著更少的樣板程式碼、更少的錯誤，以及更清晰的文件，讓前端和 QA 能更快地理解和測試 API。
*   **學習曲線**: 對於有 Python 基礎的開發者來說，FastAPI 的語法直觀且現代，上手速度很快。

### 2. 資料庫選擇：為什麼從 SQLite 開始？

*   **簡化 MVP**: 在專案初期，我們的目標是快速驗證核心功能。使用 SQLite 這個輕量級的檔案型資料庫，我們不需要設定一個獨立的資料庫伺服器（像 PostgreSQL 或 MySQL）。它直接在一個檔案 (`test.db`) 中運作，做到了「開箱即用」。
*   **無縫轉移**: 我們使用了 SQLAlchemy 這個 ORM (物件關聯對映) 工具。這意味著我們的應用程式邏輯與特定的資料庫是解耦的。當未來專案需要擴展時，我們只需要更改資料庫連接字串，就可以輕鬆地從 SQLite 遷移到更強大的資料庫，而不需要重寫大量的查詢邏輯。
*   **`check_same_thread`**: 這是 SQLite 的一個特定設定。因為 FastAPI 的非同步特性，它可能在不同的執行緒中處理同一個請求，而 SQLite 預設不允許這樣做。將此參數設為 `False` 是讓它們協同工作的標準做法。

### 3. API 端點設計的思考

*   `POST /api/urls`: 這是 RESTful 風格的標準實踐。`POST` 用於「建立」新資源。將其放在 `/api/` 路徑下是為了將來與前端路由（例如根路徑的重定向）明確區分開。
*   `GET /{short_key}`: 這是我們服務的核心。使用者直接在瀏覽器中輸入短網址，我們透過 `GET` 請求捕捉 `short_key` 並執行重定向。這個端點必須簡潔，所以它被放在根路徑。
*   `GET /api/info/{short_key}`: 為什麼需要這個額外的端點？有時候我們可能只想「查詢」一個短網址的資訊（例如它對應的原始網址是什麼），而不是立即重定向。提供一個獨立的 `info` 接口讓 API 的功能更靈活、更具可測試性。

### 4. 短網址生成策略

*   **隨機性與唯一性**: 我們選擇了 `[a-zA-Z0-9]` 的組合來生成一個 6 位數的短 `key`。這提供了足夠的組合數量 (超過 560 億種) 來應對 MVP 階段的需求。最關鍵的步驟是：生成 `key` 之後，**必須查詢資料庫以確保它尚未被使用**。雖然碰撞機率極低，但這是保證系統健嘮性的必要檢查。

---

## 第二章：前端 MVP 架構設計

**紀錄者：** 前端工程師

### 1. 框架選擇：為什麼是 React？

*   **元件化架構**: React 的核心思想是將 UI 拆分成一個個獨立、可複用的元件。對於我們的專案，我們可以輕易地建立一個 `URLShortener` 元件，它封裝了所有相關的邏輯（輸入、提交、顯示結果），讓程式碼更容易管理和維護。
*   **龐大的生態系**: React 擁有非常成熟的生態系統。無論是狀態管理 (Redux, Zustand)、路由 (React Router)，還是 UI 元件庫 (Material-UI, Ant Design)，都有大量的現成解決方案，可以極大地加速開發進程。
*   **開發工具**: `create-react-app` (CRA) 雖然現在提示已棄用，但它仍然是快速啟動一個標準 React 專案的有效方式。它為我們配置好了開發伺服器、熱重載、測試框架和生產環境打包等所有繁瑣的設定，讓我們可以專注於撰寫應用程式碼。未來若有更複雜的需求，我們可以轉向 Vite 或 Next.js 等更現代的工具。

### 2. 前端專案結構

*   **`frontend` 資料夾**: 將所有前端程式碼隔離在一個獨立的頂層目錄中，是管理一個全端專案的常見做法。這使得前後端可以獨立開發、獨立部署，職責劃分非常清晰。
*   **`src` 目錄**: 這是我們應用程式碼的主要存放地。我們將在這裡建立 `components` 資料夾來存放我們的 React 元件。
*   **`public` 目錄**: 存放靜態資源，例如 `index.html` (React 應用的進入點)、網站圖示 (favicon) 等。

### 3. 下一步的規劃

*   **元件開發**: 我將在 `frontend/src/` 中建立一個 `App.js` 的主要元件，並在其中實作 UI：一個輸入框、一個按鈕和一個顯示結果的區域。
*   **API 串接**: 我會使用瀏覽器內建的 `fetch` API 來與後端進行通訊。當使用者點擊按鈕時，它會向後端的 `POST /api/urls` 端點發送請求，並將回傳的短網址顯示在畫面上。

---

## 第三章：從錯誤中學習 - FastAPI 的依賴注入

**紀錄者：** 後端工程師

### 1. 錯誤現象

我們觀察到後端服務在處理 `/favicon.ico` 請求時出現了 `500 Internal Server Error`，日誌顯示 `TypeError: cannot pickle 'module' object`。

### 2. 問題診斷：`Depends` vs. 函式預設值

這個問題是理解 FastAPI (以及許多現代 Web 框架) 運作模式的絕佳案例。

*   **錯誤的寫法**: `def endpoint(db = next(get_db())): ...`

    當 Python 直譯器讀取這段程式碼時，`db = next(get_db())` 這部分**只會執行一次**，也就是在應用程式啟動、定義 `endpoint` 這個函式的時候。它會呼叫 `get_db()`，取得一個資料庫 session，並將這個 session 物件設定為 `db` 參數的**預設值**。

    結果是：所有呼叫這個 `endpoint` 的請求，如果沒有另外提供 `db` 參數，它們將會**共用同一個**在啟動時建立的 session。第一個請求結束後，`finally` 區塊會執行 `db.close()`，這個被共用的 session 就被關閉了。後續任何請求再試圖使用這個已關閉的 session，就會導致各種不可預期的錯誤，例如我們看到的 `pickle` 錯誤。

*   **正確的寫法**: `def endpoint(db: Session = Depends(get_db)): ...`

    `Depends` 是 FastAPI 的一個核心功能，它告訴 FastAPI：「這個參數 `db` 的值，**在每次有請求進來時**，都必須透過呼叫 `get_db` 這個函式來取得。」

    FastAPI 會為每個請求建立一個獨立的生命週期。在處理請求時，它會：
    1. 呼叫 `get_db()`。
    2. 執行 `try` 區塊，`yield` 一個新的 `db` session 給端點函式使用。
    3. 端點函式執行完畢，回傳響應。
    4. 無論成功或失敗，`finally` 區塊都會被執行，`db.close()` 會被呼叫，安全地關閉該請求專屬的 session。

### 3. 核心觀念

這個案例的核心是**依賴注入 (Dependency Injection)**。我們不應該在業務邏輯中手動建立和管理像資料庫連接這樣的「依賴」，而應該聲明我們「需要」一個依賴，由框架本身在適當的時機（例如每個請求）為我們「注入」這個依賴。這讓我們的程式碼更乾淨、更具可測試性，並能避免資源管理上的錯誤。

---

## 第四章：保持程式碼的現代性 - 處理棄用警告

**紀錄者：** 後端工程師

### 1. 警告訊息

在成功運行應用後，我們在後端日誌中發現了一條 `UserWarning`：`'orm_mode' has been renamed to 'from_attributes'`。

### 2. 診斷與解釋

*   **這不是錯誤**：首先要理解，`Warning` (警告) 不等於 `Error` (錯誤)。警告通常不會讓你的程式崩潰，但它是一個強烈的信號，表明你正在使用一個未來版本中可能會被移除或改變的功能。
*   **為什麼會有這個警告？**：我們專案使用的 `FastAPI` 依賴於 `Pydantic` 這個套件來做資料驗證。Pydantic 從 V1 升級到 V2 是一個重大的更新，帶來了性能提升和一些 API 的變化。其中一個變化就是，當我們希望 Pydantic 模型能夠直接從一個非字典的物件（例如我們的 SQLAlchemy ORM 物件）讀取屬性時，V1 使用的設定是 `orm_mode = True`。
*   **V2 的新語法**：在 Pydantic V2 中，這個功能的語義被闡述得更清晰，設定也被重新命名為 `from_attributes = True`。它的意思完全相同，只是換了一個更精確的名字。

### 3. 為什麼要修正警告？

作為一個好的開發實踐，我們應該盡可能地消除所有警告。

*   **前瞻性**：今天它只是一個警告，但在未來的某個 Pydantic 版本中，`orm_mode` 可能會被徹底移除。到那時，我們的程式碼將會直接報錯而無法運行。及早修正可以確保我們的專案能平滑地升級到未來的依賴版本。
*   **程式碼清晰度**：保持日誌的乾淨，可以讓我們在真正出現錯誤時，能第一時間注意到它，而不會被大量的警告訊息所淹沒。
*   **團隊協作**：一個沒有警告的專案對所有團隊成員來說都更友好，大家都能確信程式碼是建立在穩定且推薦的實踐之上的。

---

## 第五章：部署的基石 - Docker 容器化

**紀錄者：** DevOps 工程師

### 1. 核心問題："但在我的電腦上可以跑啊！"

在軟體開發中，最常見也最令人頭痛的問題之一，就是一個應用程式在開發者自己的電腦上運行得好好的，但一旦部署到測試環境或生產伺服器上，就因為各種原因（例如 Python 版本不同、作業系統差異、缺少某個依賴套件）而崩潰。這就是所謂的「環境不一致」問題。

### 2. Docker 的解決方案：標準化的「貨櫃」

Docker 的核心思想，是將我們的應用程式，連同它需要的所有東西（程式碼、函式庫、系統工具、執行環境），全部打包在一起，放進一個標準化、隔離化的「容器 (Container)」中。

*   **就像貨運的貨櫃**：無論裡面裝的是家具、汽車還是香蕉，貨櫃的標準尺寸和接口讓它可以在任何港口、貨船或卡車上被一致地處理。同樣地，一個 Docker 化的應用程式，無論它裡面是 Python/FastAPI 還是 Node.js/React，都可以在任何安裝了 Docker 的機器上被一致地運行。

### 3. 關鍵概念

*   **`Image` (映像檔)**：一個唯讀的範本，包含了應用程式執行所需的一切。你可以把它想像成一個「作業系統 + 應用程式」的快照，或者一個未被實例化的類別 (Class)。
*   **`Dockerfile` (Docker 檔案)**：一個純文字檔案，裡面包含了一步步的指令，告訴 Docker 如何去建立一個 Image。它就像是烤蛋糕的食譜，定義了需要哪些材料（基礎映像、原始碼、依賴）以及製作步驟（安裝、複製、執行）。
*   **`Container` (容器)**：一個 Image 的運行實例。它是真正活動的、在運行的東西。你可以從同一個 Image 啟動任意多個獨立的、互不干擾的 Container。它就像是用同一個蛋糕食譜烤出來的多個蛋糕。

### 4. 我們為 LinkZip 制定的計畫

1.  **建立 `requirements.txt`**：首先，我們會將後端服務所需的所有 Python 套件（fastapi, uvicorn, sqlalchemy）明確地列在一個清單檔案中。
2.  **建立 `.dockerignore`**：我們會告訴 Docker 在打包時要忽略哪些檔案（例如 `venv` 虛擬環境、`__pycache__` 快取檔案），以保持 Image 的輕量。
3.  **撰寫 `Dockerfile`**：我們將為後端應用建立一個 `Dockerfile`。它會：
    *   從一個官方的 Python 映像開始。
    *   安裝 `requirements.txt` 中列出的所有依賴。
    *   將我們的 `src` 目錄複製到映像中。
    *   指定容器啟動時要執行的命令 (`uvicorn ...`)。

透過這個過程，我們就能確保無論是在您的電腦、我的電腦，還是未來在 AWS 的雲端伺服器上，我們的後端服務都能以完全相同的方式、在完全相同的環境中運行。

---

## 第六章：建立安全網 - 自動化測試

**紀錄者：** QA 工程師

### 1. 為什麼要測試？

寫程式就像蓋房子，而測試就像是房子的品管和壓力測試。如果沒有測試，我們無法確定房子是否穩固，一次小小的改動（例如移動一根樑柱）有沒有可能導致整棟建築倒塌。

自動化測試為我們提供了一個「安全網」。每當我們修改程式碼或添加新功能時，我們都可以快速地運行所有測試，確保舊有的功能沒有被意外破壞。這讓我們對自己的程式碼更有信心，也讓未來的重構和擴展變得更安全、更有效率。

### 2. 我們的測試工具

*   **`pytest`**：這是 Python 社群最流行、最強大的測試框架。它讓撰寫測試案例變得非常簡單直觀，並且擁有豐富的插件生態系統。
*   **`httpx`**：為了測試我們的 API，我們需要一個 HTTP 客戶端來模擬瀏覽器或前端應用，向我們的 API 發送請求。`httpx` 是一個現代的 HTTP 客戶端，它完美支援 FastAPI 所使用的非同步特性。

### 3. 測試的核心原則：隔離

測試必須是**獨立**且**可重複**的。一個測試不應該依賴於另一個測試的結果，也不應該因為執行順序的不同而產生不同的結果。更重要的是，測試**絕對不能**影響到我們真實的開發資料庫。

為此，我們將採取以下策略：

*   **獨立的測試資料庫**：我們的測試將在一個完全獨立的、僅存在於記憶體中的 SQLite 資料庫上運行。每個測試案例執行前，資料庫都是全新的；測試結束後，它就會被銷毀。這確保了測試的乾淨與隔離。
*   **覆蓋依賴 (Dependency Override)**：我們將利用 FastAPI 強大的依賴注入系統。在測試環境中，我們會告訴 FastAPI：「當 API 程式碼請求資料庫 (`Depends(get_db)`) 時，不要給它常規的資料庫，而是給它我們專為測試準備的、隔離的記憶體資料庫。」這是 FastAPI 中實現測試隔離的標準且優雅的做法。

### 4. 我們要測試什麼？

我們將針對 `main.py` 中的每個 API 端點，測試其核心的「成功路徑」和「失敗路徑」：

*   **建立短網址**：
    *   成功：給定一個有效的 URL，是否能成功返回 `201 Created` 和短網址？
    *   失敗：給定一個無效的 URL，是否能正確返回 `400 Bad Request`？
*   **重定向**：
    *   成功：訪問一個已存在的短網址，是否能成功重定向到原始網址？
    *   失敗：訪問一個不存在的短網址，是否能正確返回 `404 Not Found`？

---

## 第七章：從開發到生產 - 整合與部署

**紀錄者：** DevOps 工程師

### 1. 開發模式 vs. 生產模式

到目前為止，我們的運作模式都屬於「開發模式」。

*   **前端**：`npm start` 啟動了一個「開發伺服器」，它會監控原始碼的變動並提供「熱重載 (Hot Reloading)」，讓我們能立即看到修改後的效果。這個過程雖然方便，但伺服器本身和提供的檔案都未經優化，不適合直接面對真實用戶。
*   **後端**：`uvicorn ... --reload` 也提供了類似的熱重載功能。
*   **結論**：這種「雙伺服器」的模式對於開發來說效率極高，但對於部署和給他人測試來說，卻顯得繁瑣和低效。

### 2. 生產環境的作法：建置與託管

在生產環境中，我們的目標是**效能**、**穩定**和**簡易**。為此，我們需要將前後端整合成一個單獨運行的實體。

*   **第一步：建置前端 (`npm run build`)**
    這個指令是 React 專案的標準化流程。它會做幾件關鍵的事情：
    1.  **編譯**：將我們寫的 React (JSX) 和現代 JavaScript 程式碼，編譯成所有瀏覽器都看得懂的普通 HTML, CSS 和 JavaScript。
    2.  **打包 (Bundling)**：將我們所有的程式碼模組打包成幾個檔案。
    3.  **優化 (Minification)**：移除所有不必要的空格、換行和註解，並縮短變數名稱，極大地減小檔案體積，讓用戶能更快地載入網頁。
    最終，所有這些優化過的、準備好被部署的靜態檔案，都會被放進一個名為 `build` 的資料夾中。

*   **第二步：由後端託管前端 (Serving Static Files)**
    一旦我們有了 `frontend/build` 這個充滿靜態檔案的資料夾，我們就不再需要 `npm start` 那個開發伺服器了。我們可以讓我們的 FastAPI 後端來直接提供這些檔案。

    我們將使用 FastAPI 的 `StaticFiles` 功能，將 `frontend/build` 這個目錄「掛載 (mount)」到我們的應用程式上。這就像是告訴 FastAPI：「嘿，如果有一個請求進來，但它不符合任何 API 路徑 (例如 `/api/urls` 或 `/{short_key}` )，那你就去 `frontend/build` 這個資料夾裡找找看有沒有對應的檔案，如果有的話，就把它回傳給使用者。」

### 3. 整合後的好處

*   **單一入口**：使用者和開發者只需要啟動一個 `uvicorn` 伺服器，就可以在同一個埠（例如 8000）上同時訪問到前端介面和後端 API。
*   **簡化部署**：我們只需要部署一個東西——整合了前端的後端應用。無論是使用 Docker 還是其他方式，都變得更簡單。
*   **效能更佳**：提供的是經過優化的靜態檔案，用戶載入速度更快。

---

## 第八章：功能疊代 - 提升使用者體驗

**紀錄者：** 前端工程師

### 1. 需求分析

我們收到了兩個新需求：
1.  在介面上區分不同類型的縮網址服務（網頁、圖片、影片）。
2.  提供「一鍵複製」功能，方便使用者取得產生的短網址。

從技術角度分析，後端 API 無需變動，因為它本身就能處理任何有效的 URL。所有改動都將集中在前端，這是一次典型的「使用者體驗 (UX) 升級」。

### 2. 架構決策：元件化與可複用性

為了實現多個相似的輸入區塊，我們不應該複製貼上三次幾乎一樣的程式碼。這會造成未來維護的困難（改一個地方，就要記得改另外兩個地方）。

*   **建立可複用元件**：我們將把現有的表單邏輯，從 `App.js` 中抽離出來，建立一個獨立的、可複用的 `ShortenerForm.js` 元件。這個元件會接收 `props` (屬性)，例如標題和輸入框的提示文字，來客製化它顯示的內容。
*   **由主程式組裝**：`App.js` 的職責將變得更單純：它只需要載入並排列三個 `ShortenerForm` 元件實例，並傳入不同的標題（例如「縮網址」、「縮圖片」）即可。這完美地體現了 React 的「元件化」核心思想，讓程式碼更清晰、更易於管理。

### 3. 技術實現：「一鍵複製」功能

這個功能將使用瀏覽器內建的 `Navigator` API 來實現，具體來說是 `navigator.clipboard.writeText()`。

*   **非同步操作**：這是一個非同步函式，它會回傳一個 `Promise`。我們將使用 `async/await` 語法來處理它。
*   **安全性**：出於安全考量，現代瀏覽器只允許在「安全上下文 (Secure Context)」中（例如 HTTPS 網站，或 `localhost` 開發環境）以及由「使用者手勢 (User Gesture)」（例如點擊按鈕）觸發時，才能使用剪貼簿 API。我們的設計完全符合這些要求。
*   **使用者反饋**：僅僅複製成功是不夠的，我們還需要給使用者一個明確的視覺回饋。我會透過一個狀態 (state) 來控制按鈕的文字。當使用者點擊「複製」時，按鈕文字會短暫地變為「已複製！」，幾秒後再變回來。這種微交互 (Micro-interaction) 對於提升使用者體驗至關重要。

---

## 第九章：專案架構 - 檔案與目錄的組織方式

**紀錄者：** 架構師

一個清晰、有邏輯的目錄結構是專案成功的基石。它讓團隊成員能快速找到他們需要關注的程式碼，也讓新加入的貢獻者能一目了然。我們的專案遵循「關注點分離 (Separation of Concerns)」的核心原則。

以下是我們專案結構的導覽：

*   `/` (專案根目錄)
    *   **作用**：整個專案的起始點，放置與整個專案相關的設定檔、文件和頂層目錄。
    *   **`.git/`**: 由 Git 自動產生，存放所有版本控制的歷史紀錄。
    *   **`ai_team/`**: 我們團隊內部的溝通與開發日誌。這有助於追蹤決策過程。
    *   **`README.md`, `LICENSE`, `teach.md`**: 專案的入口文件。`README` 是給所有人的快速上手指南；`LICENSE` 是法律保障；`teach.md` 是寫給您的架構養成日誌。
    *   **`Dockerfile`, `docker-compose.yml`, `.dockerignore`**: **DevOps 的世界**。這些檔案定義了如何打包、運行和協調我們的應用服務。它們位於根目錄，因為它們需要從一個鳥瞰的視角來整合專案的所有部分（例如，複製後端原始碼、複製前端建置成果）。
    *   **`pytest.ini`, `.gitignore`**: 專案級的工具設定檔。它們需要從根目錄生效，以覆蓋整個專案。

*   `/frontend/`
    *   **作用**：**前端的世界**。這是一個完全獨立的 React 專案，擁有自己的依賴和腳本。
    *   **`package.json`**: 前端的「宣言」。它定義了這個 React 專案需要哪些 JavaScript 函式庫 (`dependencies`)，以及有哪些可用的指令 (`scripts`，例如 `npm start`, `npm run build`)。**所有 `npm` 指令都必須在此目錄下執行。**
    *   **`node_modules/`**: `npm` 根據 `package.json` 的內容，下載下來的所有 JavaScript 函式庫都存放在這裡。這個目錄體積龐大，通常不會被提交到 Git。
    *   **`src/`**: 我們編寫的所有 React 元件和前端邏輯的家。
    *   **`build/`**: 當我們執行 `npm run build` 時，React 會將 `src` 裡原始碼編譯、打包、優化成最終的靜態 HTML/CSS/JS 檔案，並存放在這裡。這是**生產環境的成果**，也是我們最終要部署給使用者看的東西。

*   `/src/` (根目錄下的 src)
    *   **作用**：**後端的世界**。我們所有用 Python 和 FastAPI 編寫的 API 邏輯都存放在這裡。

*   `/tests/`
    *   **作用**：**QA 的世界**。存放所有針對後端 API 的 `pytest` 測試案例。保持測試程式碼與應用程式碼分離，是一種乾淨的實踐。

*   `/venv/`
    *   **作用**：Python 的「虛擬環境」。它像一個獨立的沙盒，存放著後端專案所需的所有 Python 套件 (`requirements.txt` 中定義的)，避免與您電腦上其他 Python 專案的依賴產生衝突。

---

## 第十章：邁向生產 - 引入 Docker Compose 與 PostgreSQL

**紀錄者：** 架構師

隨著專案的成熟，我們需要從「能用」的開發環境，轉向「可靠」的生產級架構。這次升級的核心，是引入 `Docker Compose` 和 `PostgreSQL`。

### 1. 為什麼需要 Docker Compose？

我們之前用 `Dockerfile` 將後端應用打包成一個獨立的容器，這很棒。但一個真實的應用，通常是**多個服務的組合**。在我們的例子中，至少有「Web 應用」和「資料庫」兩個服務。

`Docker Compose` 就像一個「總指揮」，它允許我們在一個 `docker-compose.yml` 檔案中，定義這個多服務應用的所有組件，以及它們之間的關係（例如，後端應用**依賴於**資料庫）。然後，我們可以用 `docker-compose up` 一個指令，就啟動、串連並運行所有服務。這就是「基礎設施即程式碼」的體現，它讓複雜的環境設定變得簡單、可重複且易於版本控制。

### 2. 為什麼從 SQLite 換成 PostgreSQL？

*   **SQLite 的侷限**：SQLite 是一個「嵌入式」資料庫，它直接在一個檔案中讀寫，並與我們的應用程式在同一個進程中運行。這在開發或低流量場景下非常方便，但它不擅長處理**多個同時發生的寫入操作**，在高併發下會有效能瓶頸和鎖定問題。
*   **PostgreSQL 的優勢**：PostgreSQL 是一個強大的「主從式 (Client-Server)」資料庫。它作為一個獨立的、永遠在線的服務運行。我們的 FastAPI 應用作為「客戶端 (Client)」去連接它。這種架構帶來了幾個關鍵好處：
    1.  **高併發處理**：天生為處理大量同時連線而設計。
    2.  **資料完整性**：提供更嚴格的資料型別和約束，確保資料品質。
    3.  **可擴展性**：擁有更多高級功能（如複雜查詢、索引、複寫），能支撐未來更複雜的功能需求。
    4.  **穩定性**：作為一個獨立服務，它的穩定性、備份和還原機制都遠比檔案型資料庫成熟。

### 3. 如何管理敏感資訊？

在 `docker-compose.yml` 中，我們為 PostgreSQL 設定了使用者和密碼。同時，我們修改了 `main.py`，讓它從「環境變數」中讀取資料庫連接資訊。這是一個至關重要的安全實踐。

*   **程式碼與設定分離**：我們永遠不應該將密碼、API 金鑰等敏感資訊直接寫在程式碼裡。透過環境變數，我們將**程式碼**（不變的邏輯）與**設定**（可變的、敏感的資訊）分開。這樣，我們的開源程式碼是安全的，而每個部署環境（開發、測試、生產）都可以有自己獨立的、私密的設定。

---

## 第十一章：容器編排的藝術 - 解決服務啟動依賴問題

**紀錄者：** 架構師

### 1. 問題：`depends_on` 的美麗誤會

在 `docker-compose.yml` 中，我們設定了 `backend` 服務 `depends_on: - db`。直覺上，我們會認為這代表「等到 `db` 服務完全準備好之後，再啟動 `backend`」。

但這是一個常見的誤解。`depends_on` 只保證了容器的**啟動順序**，它不關心容器**內部**的應用程式是否已經準備好接受連線。這就導致了一個典型的「競態條件」：我們的 `backend` 容器啟動得非常快，在它開始運行 `uvicorn` 並嘗試連接資料庫時，`db` 容器雖然已經啟動，但其內部的 PostgreSQL 服務可能還在進行自己的初始化（建立資料檔案、設定使用者等），還沒開始監聽網路埠。結果就是，後端的連線請求被無情地「Connection refused」。

### 2. 解決方案：從「依賴啟動」到「依賴就緒」

這個問題的解決方案，是容器化部署中的一個標準模式 (Standard Pattern)。我們不能只依賴外部的編排工具，應用程式本身也需要具備一定的「韌性 (Resilience)」。

*   **引入健康檢查腳本**：我們引入了一個廣泛使用的 shell 腳本 `wait-for-it.sh`。它的作用非常單純：不斷地去「敲」一個指定主機和埠的「門」（建立一個 TCP 連線），直到能敲開為止，然後才執行後續的指令。

*   **修改啟動指令**：我們修改了 `docker-compose.yml` 中 `backend` 服務的 `command`。原本的指令是直接啟動 `uvicorn`，現在變成了：
    ```yaml
    command: ["./wait-for-it.sh", "db:5432", "--", "uvicorn", ...]
    ```
    這行指令的意思是：「嘿，容器，在你啟動時，請先執行 `./wait-for-it.sh` 這個腳本。讓它去持續檢查 `db` 服務的 `5432` 埠。等腳本確認連線成功後，再執行 `--` 後面的主程式 `uvicorn`。」

### 3. 核心觀念：應用程式的健康檢查

這個小小的腳本，體現了分散式系統中的一個核心概念：**服務不應該盲目地假設它的依賴項永遠是可用的**。一個健壯的服務，應該在啟動時主動檢查其依賴項的健康狀況，並在依賴項不可用時，優雅地等待或重試，而不是直接崩潰。這大大提升了整個系統在動態的容器環境中的穩定性和可靠性。

